{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7e91607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (1.5.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (3.0.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (4.44.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from sentence-transformers) (0.24.5)\n",
      "Requirement already satisfied: Pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (2.11.3)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn sentence-transformers transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "702a40fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tf-keras in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow<2.18,>=2.17 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tf-keras) (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow<2.18,>=2.17->tf-keras) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (1.64.0)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (1.24.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.38.4)\n",
      "Requirement already satisfied: rich in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2023.7.22)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (1.0.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow<2.18,>=2.17->tf-keras) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00d5e2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim==4.3.0 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from gensim==4.3.0) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from gensim==4.3.0) (1.10.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim==4.3.0) (5.2.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from gensim==4.3.0) (2.0.9)\n",
      "Requirement already satisfied: Cython==0.29.32 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from gensim==4.3.0) (0.29.32)\n",
      "Requirement already satisfied: pandas in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from FuzzyTM>=0.4.0->gensim==4.3.0) (1.5.3)\n",
      "Requirement already satisfied: pyfume in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from FuzzyTM>=0.4.0->gensim==4.3.0) (0.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim==4.3.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim==4.3.0) (2023.3.post1)\n",
      "Requirement already satisfied: simpful==2.12.0 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim==4.3.0) (2.12.0)\n",
      "Requirement already satisfied: fst-pso==1.8.1 in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim==4.3.0) (1.8.1)\n",
      "Requirement already satisfied: miniful in c:\\users\\joyal\\appdata\\roaming\\python\\python311\\site-packages (from fst-pso==1.8.1->pyfume->FuzzyTM>=0.4.0->gensim==4.3.0) (0.0.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->FuzzyTM>=0.4.0->gensim==4.3.0) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim==4.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ea2c03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65da62a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comic_name</th>\n",
       "      <th>active_years</th>\n",
       "      <th>issue_title</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>issue_description</th>\n",
       "      <th>penciler</th>\n",
       "      <th>writer</th>\n",
       "      <th>cover_artist</th>\n",
       "      <th>Imprint</th>\n",
       "      <th>Format</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Year of Marvels: April Infinite Comic (2016)</td>\n",
       "      <td>(2016)</td>\n",
       "      <td>A Year of Marvels: April Infinite Comic (2016) #1</td>\n",
       "      <td>April 01, 2016</td>\n",
       "      <td>The Infinite Comic that will have everyone tal...</td>\n",
       "      <td>Yves Bigerel</td>\n",
       "      <td>Yves Bigerel</td>\n",
       "      <td>Jamal Campbell</td>\n",
       "      <td>Marvel Universe</td>\n",
       "      <td>Infinite Comic</td>\n",
       "      <td>Rated T+</td>\n",
       "      <td>Free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Year of Marvels: August Infinite Comic (2016)</td>\n",
       "      <td>(2016)</td>\n",
       "      <td>A Year of Marvels: August Infinite Comic (2016...</td>\n",
       "      <td>August 10, 2016</td>\n",
       "      <td>It’s August, and Nick Fury is just in time to ...</td>\n",
       "      <td>Jamal Campbell</td>\n",
       "      <td>Chris Sims, Chad Bowers</td>\n",
       "      <td>None</td>\n",
       "      <td>Marvel Universe</td>\n",
       "      <td>Infinite Comic</td>\n",
       "      <td>None</td>\n",
       "      <td>Free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Year of Marvels: February Infinite Comic (2016)</td>\n",
       "      <td>(2016)</td>\n",
       "      <td>A Year of Marvels: February Infinite Comic (20...</td>\n",
       "      <td>February 10, 2016</td>\n",
       "      <td>Join us in a brand new Marvel comics adventure...</td>\n",
       "      <td>Danilo S. Beyruth, M Mast</td>\n",
       "      <td>Ryan North</td>\n",
       "      <td>None</td>\n",
       "      <td>Marvel Universe</td>\n",
       "      <td>Infinite Comic</td>\n",
       "      <td>Rated T+</td>\n",
       "      <td>Free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Year of Marvels: July Infinite Comic (2016)</td>\n",
       "      <td>(2016)</td>\n",
       "      <td>A Year of Marvels: July Infinite Comic (2016) #1</td>\n",
       "      <td>June 29, 2016</td>\n",
       "      <td>Celebrating the Fourth of July is complicated ...</td>\n",
       "      <td>Juanan Ramirez</td>\n",
       "      <td>Chuck Wendig</td>\n",
       "      <td>Jamal Campbell</td>\n",
       "      <td>Marvel Universe</td>\n",
       "      <td>Infinite Comic</td>\n",
       "      <td>None</td>\n",
       "      <td>Free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Year of Marvels: June Infinite Comic (2016)</td>\n",
       "      <td>(2016)</td>\n",
       "      <td>A Year of Marvels: June Infinite Comic (2016) #1</td>\n",
       "      <td>June 15, 2016</td>\n",
       "      <td>Sam Alexander’s finding it hard to cope with t...</td>\n",
       "      <td>Diego Olortegui</td>\n",
       "      <td>Paul Allor</td>\n",
       "      <td>Jamal Campbell</td>\n",
       "      <td>Marvel Universe</td>\n",
       "      <td>Infinite Comic</td>\n",
       "      <td>None</td>\n",
       "      <td>Free</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          comic_name active_years  \\\n",
       "0     A Year of Marvels: April Infinite Comic (2016)       (2016)   \n",
       "1    A Year of Marvels: August Infinite Comic (2016)       (2016)   \n",
       "2  A Year of Marvels: February Infinite Comic (2016)       (2016)   \n",
       "3      A Year of Marvels: July Infinite Comic (2016)       (2016)   \n",
       "4      A Year of Marvels: June Infinite Comic (2016)       (2016)   \n",
       "\n",
       "                                         issue_title       publish_date  \\\n",
       "0  A Year of Marvels: April Infinite Comic (2016) #1     April 01, 2016   \n",
       "1  A Year of Marvels: August Infinite Comic (2016...    August 10, 2016   \n",
       "2  A Year of Marvels: February Infinite Comic (20...  February 10, 2016   \n",
       "3   A Year of Marvels: July Infinite Comic (2016) #1      June 29, 2016   \n",
       "4   A Year of Marvels: June Infinite Comic (2016) #1      June 15, 2016   \n",
       "\n",
       "                                   issue_description  \\\n",
       "0  The Infinite Comic that will have everyone tal...   \n",
       "1  It’s August, and Nick Fury is just in time to ...   \n",
       "2  Join us in a brand new Marvel comics adventure...   \n",
       "3  Celebrating the Fourth of July is complicated ...   \n",
       "4  Sam Alexander’s finding it hard to cope with t...   \n",
       "\n",
       "                    penciler                   writer    cover_artist  \\\n",
       "0               Yves Bigerel             Yves Bigerel  Jamal Campbell   \n",
       "1             Jamal Campbell  Chris Sims, Chad Bowers            None   \n",
       "2  Danilo S. Beyruth, M Mast               Ryan North            None   \n",
       "3             Juanan Ramirez             Chuck Wendig  Jamal Campbell   \n",
       "4            Diego Olortegui               Paul Allor  Jamal Campbell   \n",
       "\n",
       "            Imprint           Format     Rating  Price  \n",
       "0   Marvel Universe   Infinite Comic   Rated T+   Free  \n",
       "1   Marvel Universe   Infinite Comic       None   Free  \n",
       "2   Marvel Universe   Infinite Comic   Rated T+   Free  \n",
       "3   Marvel Universe   Infinite Comic       None   Free  \n",
       "4   Marvel Universe   Infinite Comic       None   Free  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Marvel_Comics.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02b8bf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\joyal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\joyal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\joyal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalpha() and token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Preprocess all descriptions\n",
    "df['tokens'] = df['issue_description'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c827851",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(df['tokens'])\n",
    "corpus = [dictionary.doc2bow(text) for text in df['tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c7632b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = LdaModel(corpus, num_topics=5, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7db948c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: 0.136*\"none\" + 0.023*\"punisher\" + 0.018*\"frank\" + 0.018*\"fury\" + 0.014*\"nick\" + 0.012*\"castle\" + 0.008*\"war\" + 0.007*\"soldier\" + 0.007*\"winter\" + 0.006*\"doc\"\n",
      "Topic 2: 0.008*\"must\" + 0.007*\"find\" + 0.006*\"save\" + 0.006*\"battle\" + 0.006*\"new\" + 0.005*\"power\" + 0.005*\"take\" + 0.005*\"strange\" + 0.005*\"help\" + 0.004*\"man\"\n",
      "Topic 3: 0.015*\"story\" + 0.014*\"marvel\" + 0.011*\"new\" + 0.010*\"comic\" + 0.010*\"series\" + 0.009*\"hulk\" + 0.009*\"issue\" + 0.007*\"artist\" + 0.007*\"first\" + 0.007*\"tale\"\n",
      "Topic 4: 0.013*\"mutant\" + 0.012*\"one\" + 0.012*\"new\" + 0.010*\"wolverine\" + 0.008*\"part\" + 0.007*\"life\" + 0.006*\"team\" + 0.006*\"find\" + 0.006*\"world\" + 0.006*\"get\"\n",
      "Topic 5: 0.021*\"marvel\" + 0.019*\"avenger\" + 0.013*\"thor\" + 0.012*\"hero\" + 0.012*\"universe\" + 0.011*\"man\" + 0.009*\"new\" + 0.009*\"four\" + 0.009*\"war\" + 0.009*\"world\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(f\"Topic {idx+1}: {topic}\")\n",
    "\n",
    "def assign_topic(text):\n",
    "    bow = dictionary.doc2bow(text)\n",
    "    topics = lda_model.get_document_topics(bow)\n",
    "    return max(topics, key=lambda x: x[1])[0]\n",
    "\n",
    "df['topic'] = df['tokens'].apply(assign_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3e362f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joyal\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "description_embeddings = model.encode(df['issue_description'].tolist(), convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd3ed760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_characters(text):\n",
    "    return re.findall(r'\\b[A-Z][a-z]+\\b', text)\n",
    "\n",
    "df['characters'] = df['issue_title'].apply(extract_characters) + df['issue_description'].apply(extract_characters)\n",
    "df['characters'] = df['characters'].apply(lambda x: ', '.join(set(x)))\n",
    "\n",
    "# Encode characters\n",
    "character_embeddings = model.encode(df['characters'].tolist(), convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a73604db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_comics(query, df, lda_model, dictionary, description_embeddings, character_embeddings, writer_column, model, top_n=5):\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Check if query is related to a writer\n",
    "    if any(writer.lower() in query_lower for writer in df[writer_column].str.lower().unique()):\n",
    "        filtered_df = df[df[writer_column].str.contains(query, case=False, na=False)]\n",
    "        return filtered_df.head(top_n)\n",
    "\n",
    "    # Check if query is related to characters/teams\n",
    "    if re.search(r'\\b[A-Z][a-z]+\\b', query):\n",
    "        query_embedding = model.encode([query], convert_to_tensor=True)\n",
    "        cosine_sim = util.pytorch_cos_sim(query_embedding, character_embeddings)[0]\n",
    "        # Ensure cosine_sim has valid indices\n",
    "        if len(cosine_sim) == 0:\n",
    "            return pd.DataFrame()  # Return empty DataFrame if no character embeddings are found\n",
    "        recommended_indices = cosine_sim.argsort(descending=True)[:top_n]\n",
    "        return df.iloc[recommended_indices]\n",
    "    \n",
    "    # Default to description-based recommendation\n",
    "    # Determine the topic of the query using LDA\n",
    "    query_tokens = preprocess(query)\n",
    "    bow = dictionary.doc2bow(query_tokens)\n",
    "    topics = lda_model.get_document_topics(bow)\n",
    "    if not topics:\n",
    "        return pd.DataFrame()  # Return empty DataFrame if no topics found\n",
    "    \n",
    "    # Get the most relevant topic\n",
    "    topic = max(topics, key=lambda x: x[1])[0]\n",
    "    \n",
    "    # Filter comics based on the topic\n",
    "    filtered_df = df[df['topic'] == topic]\n",
    "    \n",
    "    if filtered_df.empty:\n",
    "        return pd.DataFrame()  # Return empty DataFrame if no comics in the topic\n",
    "    \n",
    "    # Apply semantic similarity\n",
    "    filtered_embeddings = model.encode(filtered_df['issue_description'].tolist(), convert_to_tensor=True)\n",
    "    query_embedding = model.encode([query], convert_to_tensor=True)\n",
    "    \n",
    "    cosine_sim = util.pytorch_cos_sim(query_embedding, filtered_embeddings)[0]\n",
    "    \n",
    "    # Ensure cosine_sim has valid indices\n",
    "    if len(cosine_sim) == 0:\n",
    "        return pd.DataFrame()  # Return empty DataFrame if no description embeddings are found\n",
    "    \n",
    "    recommended_indices = cosine_sim.argsort(descending=True)[:top_n]\n",
    "    \n",
    "    return filtered_df.iloc[recommended_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "171f6ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['comic_name', 'active_years', 'issue_title', 'publish_date',\n",
      "       'issue_description', 'penciler', 'writer', 'cover_artist', 'Imprint',\n",
      "       'Format', 'Rating', 'Price', 'tokens', 'topic', 'characters'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "464ac0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 comic_name                       issue_title  \\\n",
      "23413     Spider-Man/Deadpool (2016 - 2019)    Spider-Man/Deadpool (2016) #42   \n",
      "13733    Journey Into Mystery (1952 - 1966)   Journey Into Mystery (1952) #11   \n",
      "25409   Strikeforce: Morituri (1986 - 1989)   Strikeforce: Morituri (1986) #4   \n",
      "14214  Lorna the Jungle Queen (1953 - 1954)  Lorna the Jungle Queen (1953) #4   \n",
      "11455         Howard the Duck (1976 - 1979)        Howard the Duck (1976) #25   \n",
      "\n",
      "                                       issue_description  \n",
      "23413              Spider-Man and Deadpool…roadtripping!  \n",
      "13733  A medium plays an 'undead' prank on another me...  \n",
      "25409  Fame glorifies the Strikeforce when a dramatic...  \n",
      "14214  Greg Knight takes a boorish stance on animal r...  \n",
      "11455  Paul takes Howard out for a night on the town ...  \n"
     ]
    }
   ],
   "source": [
    "def normalize_query(query):\n",
    "    query_lower = query.lower()\n",
    "    return query_lower.replace('by ', '').strip()\n",
    "\n",
    "# Example usage\n",
    "query = \"comedy\"  # This can be a description, character name, or writer name\n",
    "normalized_query = normalize_query(query)\n",
    "\n",
    "recommended_comics = recommend_comics(normalized_query, df, lda_model, dictionary, description_embeddings, character_embeddings, 'writer', model)\n",
    "print(recommended_comics[['comic_name', 'issue_title', 'issue_description']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abe059df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  comic_name  \\\n",
      "9523            Fantastic Four (1998 - 2012)   \n",
      "26744  The Invincible Iron Man (2004 - 2007)   \n",
      "1766           Avengers & X-Men: Axis (2014)   \n",
      "1767           Avengers & X-Men: Axis (2014)   \n",
      "30033         Uncanny Avengers (2015 - 2017)   \n",
      "\n",
      "                              issue_title  \\\n",
      "9523           Fantastic Four (1998) #504   \n",
      "26744  The Invincible Iron Man (2004) #12   \n",
      "1766     Avengers & X-Men: Axis (2014) #3   \n",
      "1767     Avengers & X-Men: Axis (2014) #2   \n",
      "30033         Uncanny Avengers (2015) #12   \n",
      "\n",
      "                                       issue_description  \n",
      "9523   AUTHORITATIVE ACTION PART 2 Nick Fury has been...  \n",
      "26744  When a dead-man's switch is triggered, the awe...  \n",
      "1766   ACT I: THE RED SUPREMACY. The heroes of the Ma...  \n",
      "1767   ACT I: THE RED SUPREMACY. The heroes of the Ma...  \n",
      "30033  All-out action to save an Avenger ...FROM ULTR...  \n"
     ]
    }
   ],
   "source": [
    "query = \"action\"  \n",
    "normalized_query = normalize_query(query)\n",
    "\n",
    "recommended_comics = recommend_comics(normalized_query, df, lda_model, dictionary, description_embeddings, character_embeddings, 'writer', model)\n",
    "print(recommended_comics[['comic_name', 'issue_title', 'issue_description']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e7c4572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: gensim\n",
      "Version: 4.3.0\n",
      "Summary: Python framework for fast Vector Space Modelling\n",
      "Home-page: http://radimrehurek.com/gensim\n",
      "Author: Radim Rehurek\n",
      "Author-email: me@radimrehurek.com\n",
      "License: LGPL-2.1-only\n",
      "Location: C:\\Users\\joyal\\AppData\\Roaming\\Python\\Python311\\site-packages\n",
      "Requires: Cython, FuzzyTM, numpy, scipy, smart-open\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "609491ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.save(character_embeddings, 'models/character_embeddings.pt')\n",
    "torch.save(description_embeddings, 'models/description_embeddings.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d4781fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.save('models/dictionary.pkl')\n",
    "lda_model.save('models/lda_model.pkl')\n",
    "model.save('models/sentence_transformer_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421f7ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
